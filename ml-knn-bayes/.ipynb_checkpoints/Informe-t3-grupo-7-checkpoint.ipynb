{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 3\n",
    "\n",
    "### Grupo 7:\n",
    "     - S. Volti  C.I. 5.175.914-7\n",
    "     - A. Sierra C.I. 4.647.235-6\n",
    "     - A. Clara C.I. 4.772.294-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta tarea son:\n",
    "- Construir clasificadores desde cero utilizando como algoritmos a KNN y Naive Bayes.\n",
    "- Construir dichos clasificadores utilizando los mismos algoritmos, pero ahora haciendo uso de las implementaciones de Scikit-Learn.\n",
    "- Evaluar y realizar una comparación entre lo implementando desde cero y lo obtenido con Scikit-Learn.\n",
    "\n",
    "El éxito del aprendizaje se mide a través de la evaluación de los clasificadores sobre un conjunto de evaluación, habiendo pasado por una etapa de validación para obtener hiper-parámetros óptimos, y haciendo uso de validación cruzada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Análisis del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden encontrar 48842 instancias en el dataset. Las clases posibles son >50 y <=50, por lo que se trata de un problema de clasificación binario. A partir de ahora, se le llaman instancias positivas a aquellas con clasificación >50, y negativas a aquellas con clasificación <=50.\n",
    "\n",
    "Hay 15 atributos en total, donde 14 de ellos son de entradas y 1 es de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Valores posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset se pueden encontrar tanto valores numéricos como valores categóricos:\n",
    "- **age:** Toma valores numéricos.\n",
    "- **workclass:** Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- **fnlwgt:** Toma valores numéricos.\n",
    "- **education:** Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- **education-num:** Toma valores numéricos.\n",
    "- **marital-status:** Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- **occupation:** Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- **relationship:** Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- **race:** White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- **sex:** Female, Male.\n",
    "- **capital-gain:** Toma valores numéricos.\n",
    "- **capital-loss:** Toma valores numéricos.\n",
    "- **hours-per-week:** Toma valores numéricos.\n",
    "- **native-country:** United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 14 atributos, hay 3 que tienen instancias con valores faltantes:\n",
    "- **workclass:** 2799 valores faltantes.\n",
    "- **occupation:** 2809 valores faltantes.\n",
    "- **native-country:** 857 valores faltantes.\n",
    "\n",
    "En total hay 6465 valores faltantes y 3620 (7.41% del total) instancias con algún valor faltante. En todos los casos se trata de atributos categóricos.\n",
    "\n",
    "No se marcan con un valor especial porque el hecho de no tener un valor asignado no tiene un significado que aporte al momento de clasificar (por ejemplo, el hecho de que no se haya registrado la ocupación de una persona no aporta nada al problema).\n",
    "\n",
    "Por lo tanto, para cada atributo con valores faltantes se decide llenar dichos valores con el valor más común del resto de las instancias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Distribución de la clase objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de 48842 instancias, 37155 (76.07% del total) son positivas, y 11687 (23.93% del total) son negativas. Por lo que se puede concluir que el dataset está desbalanceado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset viene separado en dos archivos, uno pensado para el entrenamiento y otro para la evaluación. Se decide juntar todas las instancias en un solo csv, el cual será procesado y separado en los subconjuntos correspondientes, pero a nivel de Python.\n",
    "\n",
    "También se realiza la limpieza de algunos detalles en los datos. Por ejemplo, el archivo de extensión .test tiene caracteres de punto al final de la clase, los cuales son leídos por Python al momento de cargar el csv, y hace que se interpreten tres clases en lugar de dos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Discretización de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos opcionalmente discretización en “n” bins (contenedores) sobre determinados atributos del conjunto de datos, con el fin de transformar los atributos continuos en atributos categóricos. \n",
    "Esto sirve por ejemplo para convertir las edades, en grupos de rangos de edad (1-10,11-20,21-30,..) .\n",
    "Optamos por discretizar los siguientes atributos: **['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']**,  utilizando la función de pandas “qcut”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Normalización de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos opcionalmente normalización sobre todos los atributos del conjunto de datos, trabajando siempre en el rango [0,1], con el objetivo de unificar la escala entre las características del conjunto de datos.\n",
    "La diferencia de escala entre atributos puede dar más importancia a determinados atributos sobre otros.\n",
    "Utilizamos las funciones “MinMaxScaler” y “fit_transform” de sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Implementación de KNN desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la implementación del algoritmo KNN utilizamos la librería KDTree de sklearn.neighbors.\n",
    "Para realizar KNN de forma eficiente, necesitamos definir la cantidad “k” de vecinos más cercanos que vamos a considerar para clasificar un ejemplo perteneciente al conjunto de evaluación.\n",
    "También necesitamos definir la forma en que vamos a medir la distancia entre 2 ejemplos del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Implementación de Naive Bayes desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la implementación de Naive Bayes primero se crea un Dataframe que contiene las probabilidades necesarias para calcular la clasificación de cada instancia del conjunto de evaluación.  \n",
    "Este dataframe contiene la probabilidad de que ocurra cada valor posible para cada atributo, calculando las mismas como la frecuencia sobre el total, asi a la hora de clasificar una instancia se recorre esta matriz multiplicando las probabilidades relacionadas con los valores que toma la misma en cada atributo.\n",
    "La matriz de probabilidades se calcula de la siguiente manera:  \n",
    "\n",
    "    prior=training_set.groupby('classification').size()  \n",
    "    for i in attributes\n",
    "      likelihood[i]=training_set.groupby(['classification',DATASET_ATTRS[i]]).size().div(prior)  \n",
    "  \n",
    "  \n",
    "Notamos al crear el dataframe, que si una instancia del conjunto de evaluación tiene para algún atributo un valor único, la probabilidad de que ocurra ese valor para cualquiera de las clasificaciones no existe en la matriz pues su frecuencia en el conjunto de entrenamiento es cero.  \n",
    "Para estos casos calculamos las probabilidades utilizando el M-estimador, donde m fue hallado mediante validación cruzada y p se calculo como  $p=1/k$ donde k en la cantidad de valores que pudo tomar un atributo en el conjunto de entranamiento.\n",
    "\n",
    "Luego para mejorar aún más el algoritmo utlizamos un algoritmo híbrido para calcular las probabilidades en los atributos continuos, dado que no es una buena practica calcular las mismas como la frecuencia sobre el total. Bajo el supuesto de que estos atributos tiene una distribución normal utilizamos la siguiente fórmula :  \n",
    "$P(x|μ,σ ^{2})=\\frac{1}{\\sqrt{2σ ^{2}π}}e^{\\frac{(x-μ)^{2}}{2σ ^{2}}}$  \n",
    "Siendo σ la desviación estándar y μ la media.\n",
    "Para calcular las mismas creamos un dataframe de la siguiente forma:  \n",
    "\n",
    "    mean_std=training_set.groupby('classification').agg([np.mean, np.std]  \n",
    "    \n",
    "Otra alternativa para los atributos reales es discretizarlos y mapearlos a intervalos de valores como se dijo en la seccion 2.2.1. Por ejemplo si los atributos continuos no tiene una distribucion normal esta es una buena técnica para transformar estos atributos contínuos en discretos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir la performance los clasificadores se particiona el conjunto de datos original en dos subconjuntos: de entrenamiento y evaluación, donde se utiliza un 80% para el entrenamiento, y el restante 20% se reserva para la evaluación.\n",
    "\n",
    "Antes de construir los subconjuntos se realiza un shuffle sobre el conjunto de datos, y luego sí se particiona dicho conjunto en dos.\n",
    "\n",
    "También se hace una etapa de validación, donde se buscan los valores óptimos para los hiper-parámetros de cada uno de los algoritmos. Para realizar esto se hace uso del concepto de validación cruzada usando 5 o 10 folds.\n",
    "\n",
    "Dado que el dataset se encuentra desbalanceado, se aplica estratificación (obligar a que la proporción entre clases sea la misma en el conjunto de entrenamiento y en el de evaluación). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Métricas utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los resultados obtenidos en todas las partes, se utilizan las medidas accuracy, precision, recall y F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Ejecución del programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La ejecución mínima del programa se debe hacer de la siguiente forma:\n",
    "\n",
    "_python3 main.py -s 5 -t 0.8 -p c\n",
    "\n",
    "donde:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th style=\"text-align: left\"><b>Parámetro</b></th>\n",
    "    <th style=\"text-align: left\"><b>Descripción</b></th>\n",
    "    <th style=\"text-align: left; width: 80px\"><b>Por defecto</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>s</b></td>\n",
    "    <td style=\"text-align: left\">Semilla utilizada por los paquetes random y numpy (para Scikit).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>t</b></td>\n",
    "    <td style=\"text-align: left\">Fracción de los ejemplos usados para el entrenamiento (0.8 = 80% de entrenamiento, 20% de evaluacion).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>p</b></td>\n",
    "    <td style=\"text-align: left\">Parte del main a ejecutar (a ejecuta la parte a, etc).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>d</td>\n",
    "    <td style=\"text-align: left\">Nivel de debug para los prints (0 no imprime nada, 1 solo información, 2 datos para debugging).</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>c</td>\n",
    "    <td style=\"text-align: left\">Indica con c > 0 la cantidad de iteraciones con la que se realizará validación cruzada.</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>i</td>\n",
    "    <td style=\"text-align: left\">\n",
    "Si i > 0, se preprocesan los valores numéricos del dataset, discretizándolos en i bins\n",
    "</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>n</td>\n",
    "    <td style=\"text-align: left\">Si n > 0, se preprocesan los valores numéricos del dataset, normalizandolos entre 0 y 1</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k</td>\n",
    "    <td style=\"text-align: left\">k indica la cantidad de vecinos mas cercanos que utiliza knn</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m</td>\n",
    "    <td style=\"text-align: left\">m indica el parámetro de suavizado categórico para Naive Bayes</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Observación:** Los parámetros s, t y p son obligatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Distribución de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la experimentación con las distintas implementaciones utilizadas, pudimos notar que los resultados obtenidos con la implementación de Naive Bayes que asume que los atributos numéricos siguen una distribución normal, siempre eran peores que los que utilizan Naive Bayes asumiendo que los atributos son categóricos. Esto nos dio a pensar que tal vez existiera la posibilidad de que los atributos numéricos, en realidad, pudieran no seguir una distribución normal.\n",
    "\n",
    "Para verificar esto, se hizo uso de los tests de normalidad ofrecidos por el paquete stats de scipy. En particular, se usó el método normaltest.\n",
    "\n",
    "Dada la hipótesis nula de que los datos vinieron de una distribución normal, tomando un alfa=0.05 como umbral:\n",
    "\n",
    "En todos los tests normales aplicados a las distribuciones de los distintos atributos, se obtuvieron ms o bien iguales a 0, o menores a 1x10^-247. Por lo que se puede rechazar la hipótesis nula, y concluir que los datos no siguen una distribución normal.\n",
    "\n",
    "Para ejecutar el código correspondiente a estas pruebas, se puede usar el siguiente comando:\n",
    "\n",
    "_python3 dataset_analysis.py_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Nuestras implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Ejecución de KNN nuestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import utils\n",
    "\n",
    "########## PARÁMETROS DE EJECUCIÓN ##########\n",
    "\n",
    "SEED = 3\n",
    "DISCR = 0              # Cantidad de bins utilizado para la discretización de los atributos continuos\n",
    "NORM = 1               # 1 si se quiere normalizar, 0 en caso contrario\n",
    "TSET_PERCENTAGE = 0.8  # Proporción utilizada para el set de entrenamiento\n",
    "K = 11                 # Cantidad de vecinos para KNN\n",
    "\n",
    "params = [DISCR, NORM, TSET_PERCENTAGE]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "training_examples, training_classes, evaluation_examples, evaluation_classes, training_set, evaluation_set = utils.prepare_data(*params)\n",
    "\n",
    "logging.info(f\"Ejecutando KNN nuestro...\")\n",
    "results_classes, evaluation_classes = knn.knn(training_examples, training_classes, evaluation_examples, evaluation_classes, K)\n",
    "metrics = utils.get_metrics(results_classes, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"KNN nuestro finalizado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Validación cruzada con KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.1. Implementación inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestra implementación inicial, trabajando siempre con atributos estandarizados, utilizamos la distancia euclídea como métrica, y realizamos validación cruzada de 10 iteraciones sobre el conjunto de entrenamiento, con el fin de encontrar el valor de “k” que determina mejores resultados.\n",
    "\n",
    "Para ésto probamos con un rango de valores impares de “k” bastante grande, que van desde 1 a 15.\n",
    "Utilizamos valores impares para no tener que lidiar con empates a la hora de clasificar determinado ejemplo, ya que en principio determinamos la clasificación de un ejemplo en base a la clase con mayor cantidad de apariciones en sus vecinos más cercanos (si determinada instancia tiene 2 vecinos más cercanos de clase negativa, y 1 vecino más cercano de clase positiva, se le asignará a la instancia la clase negativa).\n",
    "\n",
    "Como lo dice el algoritmo, la idea es seleccionar los vecinos más cercanos, por lo que incrementar el rango de “k” no sería conveniente, ya que para clasificar a determinada instancia, nos estamos basando en otras instancias que no son tan relevantes (ya que no son vecinos cercanos).\n",
    "\n",
    "Detallamos a continuación los resultados de efectuar validación cruzada de 10 folds para cada hiperparámetro “k” estudiado:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2. Implementación sin discretización ni normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "      <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>k=1</td>\n",
    "    <td>73.77%</td>\n",
    "    <td>45.31%</td>\n",
    "    <td>48.29%</td>\n",
    "    <td>46.74%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=3</td>\n",
    "    <td>76.67%</td>\n",
    "    <td>51.33%</td>\n",
    "    <td>41.96%</td>\n",
    "    <td>46.16%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=5</td>\n",
    "    <td>77.69%</td>\n",
    "    <td>54.72%</td>\n",
    "    <td>37.48%</td>\n",
    "    <td>44.48%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=7</td>\n",
    "    <td>78.57%</td>\n",
    "    <td>58.74%</td>\n",
    "    <td>33.96%</td>\n",
    "    <td>43.02%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=9</td>\n",
    "    <td>78.97%</td>\n",
    "    <td>61.89%</td>\n",
    "    <td>30.71%</td>\n",
    "    <td>41.03%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=11</td>\n",
    "    <td>79.07%</td>\n",
    "    <td>64.13%</td>\n",
    "    <td>27.76%</td>\n",
    "    <td>38.73%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=13</td>\n",
    "    <td>79.34%</td>\n",
    "    <td>67.55%</td>\n",
    "    <td>25.75%</td>\n",
    "    <td>37.28%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=15</td>\n",
    "    <td>79.51%</td>\n",
    "    <td>70.93%</td>\n",
    "    <td>23.84%</td>\n",
    "    <td>35.67%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - KNN -s = 5, d = 80/20</caption>\n",
    "</table>  \n",
    "\n",
    "Notamos claramente que a medida que incrementamos “K”,  Accuracy y Precision van en ascenso, y por otro lado Recall y F1 en descenso.\n",
    "A medida que incrementamos “K”, logramos clasificar más ejemplos de la clase negativa (las instancias <= 50k) correctamente, pero la cantidad de instancias positivas clasificadas correctamente disminuye.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.3. Implementación discretizada (10 bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "      <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>k=1</td>\n",
    "    <td>77.48%</td>\n",
    "    <td>52.73%</td>\n",
    "    <td> 54.03%</td>\n",
    "    <td>53.36%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=3</td>\n",
    "    <td>80.29%</td>\n",
    "    <td>59.14%</td>\n",
    "    <td>56.05%</td>\n",
    "    <td>57.54%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=5</td>\n",
    "    <td>81.07%</td>\n",
    "    <td>61.22%</td>\n",
    "    <td>56.34%</td>\n",
    "    <td>58.66%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=7</td>\n",
    "    <td>81.33%</td>\n",
    "    <td>61.98%</td>\n",
    "    <td>56.28%</td>\n",
    "    <td>58.98%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=9</td>\n",
    "    <td>81.53%</td>\n",
    "    <td>62.51%</td>\n",
    "    <td>56.44%</td>\n",
    "    <td>59.30%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=11</td>\n",
    "    <td>81.61%</td>\n",
    "    <td>63.34%</td>\n",
    "    <td>56.34%</td>\n",
    "    <td>59.63%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=13</td>\n",
    "    <td>81.81%</td>\n",
    "    <td>63.34%</td>\n",
    "    <td>59.63%</td>\n",
    "    <td>37.28%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=15</td>\n",
    "    <td>81.78%</td>\n",
    "    <td>63.36%</td>\n",
    "    <td>56.04%</td>\n",
    "    <td>59.46%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - KNN -s = 5, d = 80/20</caption>\n",
    "</table>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.4. Implementación normalizada rango (0-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "      <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>k=1</td>\n",
    "    <td>80.36%</td>\n",
    "    <td>58.68%</td>\n",
    "    <td>59.74%</td>\n",
    "    <td>59.20%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=3</td>\n",
    "    <td>82.73%</td>\n",
    "    <td>64.76%</td>\n",
    "    <td>60.55%</td>\n",
    "    <td>62.57%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=5</td>\n",
    "    <td>83.51%</td>\n",
    "    <td>66.95%</td>\n",
    "    <td>60.97%</td>\n",
    "    <td>63.81%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=7</td>\n",
    "    <td>83.96%</td>\n",
    "    <td>68.04%</td>\n",
    "    <td>61.74%</td>\n",
    "    <td>64.73%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=9</td>\n",
    "    <td>84.26%</td>\n",
    "    <td>68.87%</td>\n",
    "    <td>62.00%</td>\n",
    "    <td>65.25%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=11</td>\n",
    "    <td>84.29%</td>\n",
    "    <td>69.08%</td>\n",
    "    <td>61.74%</td>\n",
    "    <td>65.19%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=13</td>\n",
    "    <td>84.29%</td>\n",
    "    <td>69.14%</td>\n",
    "    <td>61.66%</td>\n",
    "    <td>65.18%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=15</td>\n",
    "    <td>84.47%</td>\n",
    "    <td>69.65%</td>\n",
    "    <td>61.83%</td>\n",
    "    <td>65.50%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - KNN -s = 5, d = 80/20</caption>\n",
    "</table>  \n",
    "\n",
    "Aquí vemos que trabajando sobre un conjunto de datos de entrenamiento discretizado o normalizado, obtenemos mejores métricas, menos varianza en los resultados, y no sólo eso, todas las métricas van en ascenso hasta trabajar con “k” = 9, luego tanto Recall como F1 comienzan a disminuir levemente.\n",
    "Además, trabajar con atributos normalizados implica una mejora respecto de trabajar con atributos discretizados.\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.5. Implementación quitando atributos poco relevantes del conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que tanto el atributo “fnlwgt” como el atributo “relationship” no son relevantes a la hora de analizar cómo clasifica determinada instancia.\n",
    "El primero de estos no representa ningún dato concreto de la realidad, según su definición hace referencia a la cantidad de instancias que se “cree” que la instancia dada representa en realidad. Además, el mismo está plagado de valores “0”, por lo que decidimos removerlo para el estudio realizado con KNN. \n",
    "Lo mismo sucede con el atributo “relationship”, ya que el mismo hace referencia a qué relación tiene esa instancia (persona) con otra. \n",
    "Además, lo notamos redundante con el campo que indica el estado civil de la instancia en cuestión, por lo que también decidimos removerlo. \n",
    "\n",
    "Entonces, realizamos una última pasada de validación cruzada con 10 iteraciones, en las condiciones que detallamos anteriormente, con un conjunto de datos estandarizado, normalizado, y sin los atributos “fnlwgt” y “relationship”.\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "      <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>k=1</td>\n",
    "    <td>80.77%</td>\n",
    "    <td>59.45%</td>\n",
    "    <td>60.91%</td>\n",
    "    <td>60.16%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=3</td>\n",
    "    <td>82.72%</td>\n",
    "    <td>64.54%</td>\n",
    "    <td>61.13%</td>\n",
    "    <td>62.78%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=5</td>\n",
    "    <td>83.60%</td>\n",
    "    <td>67.00%</td>\n",
    "    <td>61.57%</td>\n",
    "    <td>63.81%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=7</td>\n",
    "    <td>84.23%</td>\n",
    "    <td>68.74%</td>\n",
    "    <td>62.12%</td>\n",
    "    <td>65.25%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=9</td>\n",
    "    <td>84.34%</td>\n",
    "    <td>69.22%</td>\n",
    "    <td>61.93%</td>\n",
    "    <td>65.31%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=11</td>\n",
    "    <td>84.53%</td>\n",
    "    <td>69.78%</td>\n",
    "    <td>61.74%</td>\n",
    "    <td>65.61%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=13</td>\n",
    "    <td>84.68%</td>\n",
    "    <td>70.33%</td>\n",
    "    <td>61.87%</td>\n",
    "    <td>65.83%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=15</td>\n",
    "    <td>84.61%</td>\n",
    "    <td>70.10%</td>\n",
    "    <td>61.82%</td>\n",
    "    <td>65.70%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - KNN -s = 5, d = 80/20</caption>\n",
    "</table>  \n",
    "\n",
    "Aquí podemos observar que hasta trabajar con “K” = 7 las métricas obtenidas van todas en ascenso, y luego el Recall tiende a bajar un poco, pero las diferencias son insignificantes. \n",
    "También notamos una mínima mejoría en todas las iteraciones en comparación a los resultados obtenidos estudiando todos los atributos del conjunto de datos. \n",
    "\n",
    "Por tanto podemos considerar como parámetro óptimo cualquier “k” que pertenezca al rango de valores [7,9,11,13], utilizando un conjunto de datos estandarizado, normalizado, y sin los atributos “fnlwgt” y “relationship”.\n",
    "\n",
    "Vale aclarar que también realizamos validación cruzada para valores de “k” mayores  a 15, y comprobamos que las métricas de Recall y F1 comienzan a disminuir lentamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Ejecución de Naive Bayes nuestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import naive_bayes\n",
    "import numpy as np\n",
    "import random\n",
    "import utils\n",
    "\n",
    "########## PARÁMETROS DE EJECUCIÓN ##########\n",
    "\n",
    "SEED = 3\n",
    "DISCR = 10             # Cantidad de bins utilizado para la discretización de los atributos continuos\n",
    "NORM = 1               # 1 si se quiere normalizar, 0 en caso contrario\n",
    "TSET_PERCENTAGE = 0.8  # Proporción utilizada para el set de entrenamiento\n",
    "M = 1                  # Parámetro m de suavizado categórico\n",
    "\n",
    "params = [DISCR, NORM, TSET_PERCENTAGE]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "training_examples, training_classes, evaluation_examples, evaluation_classes, training_set, evaluation_set = utils.prepare_data(*params)\n",
    "\n",
    "logging.info(f\"Ejecutando Naive Bayes nuestro...\")\n",
    "results_classes = naive_bayes.full_nb(training_set, evaluation_set, M)\n",
    "metrics = utils.get_metrics(results_classes, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"Naive Bayes nuestro finalizado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Validación cruzada con Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes tablas muestran los resultados de cada iteracion de validación cruzada con Naive Bayes.\n",
    "Primero sin discretizar los atributos contínuos y sin utilizar Gauss realizamos una corrida utilizando el algoritmo sin variaciones. Es decir, calculando todas las probabilidades como la frecuencia sobre el total. Vale aclarar que al igual que en KNN, los atributos ‘fnlwgt’, y ‘relationship’ no serán utilizados.\n",
    "Esto nos dio una primera idea sobre qué sucede con las metricas al variar el hiperparámetro m.  \n",
    "Luego si utilizamos el algoritmo híbrido utilizando la distribución gaussiana para los atributos contínuos, vimos cómo se comportaba m y tomamos las métricas sobre el conjunto de evaluacion.\n",
    "Por ultimo discretizamos y utilizamos el algoritmo de Naive Bayes sin variaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4.1. Implementación sin discretización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4.1.1. Naive Bayes Categórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Precisión</th>\n",
    "    <th>Recall</th>\n",
    "    <th>F1</th>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>m=5</b></td>\n",
    "    <td><b>85.76%</b></td>\n",
    "    <td><b>68.77%</b></td>\n",
    "    <td><b>73.82%</b></td>\n",
    "    <td><b>71.20%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=10</td>\n",
    "    <td>85.05%</td>\n",
    "    <td>67.56%</td>\n",
    "    <td>72.47%</td>\n",
    "    <td>69.93%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=100</td>\n",
    "    <td>84.78%</td>\n",
    "    <td>66.97%</td>\n",
    "    <td>71.60%</td>\n",
    "    <td>69.20%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=1500</td>\n",
    "    <td>82.76%</td>\n",
    "    <td>62.61%</td>\n",
    "    <td>69.34%</td>\n",
    "    <td>65.80%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=7000</td>\n",
    "    <td>82.48%</td>\n",
    "    <td>61.35%</td>\n",
    "    <td>69.51%</td>\n",
    "    <td>65.17%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - Naive Bayes -s = 5, d = 80/20</caption>\n",
    "</table>  \n",
    "\n",
    "  \n",
    "Esto nos hace pensar que para esta primera instancia de algoritmo a medida que m decrece tenemos mejores resultados. \n",
    "El resultado de evaluar el algoritmo con el conjunto de evaluacion y con m=5 es:  \n",
    "  \n",
    "<table style=\"display: inline-block; margin-left: 48px;\">  \n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>m=5</b></td>\n",
    "    <td><b>85.21%</b></td>\n",
    "    <td><b>68.03%</b></td>\n",
    "    <td><b>73.68%</b></td>\n",
    "    <td><b>70.74%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4.1.2. Naive Bayes Híbrido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego si utilizamos la distrubucion gaussiana para los atributos reales:  \n",
    "  \n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Precisión</th>\n",
    "    <th>Recall</th>\n",
    "    <th>F1</th>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>m=0.4</b></td>\n",
    "    <td><b>84.90%</b></td>\n",
    "    <td><b>75.79%</b></td>\n",
    "    <td><b>53.92%</b></td>\n",
    "    <td><b>63.01%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=5</td>\n",
    "    <td>83.77%</td>\n",
    "    <td>72.31%</td>\n",
    "    <td>52.40%</td>\n",
    "    <td>60.77%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=10</td>\n",
    "    <td>83.24%</td>\n",
    "    <td>70.62%</td>\n",
    "    <td>51.02%</td>\n",
    "    <td>59.24%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=100</td>\n",
    "    <td>82.62%</td>\n",
    "    <td>69.00%</td>\n",
    "    <td>49.65%</td>\n",
    "    <td>57.75%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=1500</td>\n",
    "    <td>81.62%</td>\n",
    "    <td>66.24%</td>\n",
    "    <td>45.04%</td>\n",
    "    <td>53.62%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - Naive Bayes Gauss -s = 5, d = 80/20</caption>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4.2. Implementación discretizada (10 bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4.2.1. Naive Bayes Categórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Precisión</th>\n",
    "    <th>Recall</th>\n",
    "    <th>F1</th>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>m=0.4</b></td>\n",
    "    <td><b>82.24%</b></td>\n",
    "    <td><b>61.78%</b></td>\n",
    "    <td>66.95%</td>\n",
    "    <td><b>64.26%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=5</td>\n",
    "    <td>81.51%</td>\n",
    "    <td>60.26%</td>\n",
    "    <td><b>67.24%</b></td>\n",
    "    <td>63.56%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=10</td>\n",
    "    <td>81.60%</td>\n",
    "    <td>60.52%</td>\n",
    "    <td>65.97%</td>\n",
    "    <td>63.13%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=100</td>\n",
    "    <td>81.25%</td>\n",
    "    <td>59.76%</td>\n",
    "    <td>66.19%</td>\n",
    "    <td>62.81%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m=1500</td>\n",
    "    <td>81.41%</td>\n",
    "    <td>59.28%</td>\n",
    "    <td>67.61%</td>\n",
    "    <td>63.17%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla - Naive Bayes Gauss -s = 5, d = 80/20</caption>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Evaluación comparativa entre implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos al evaluar con el conjunto de entrenamiento los algoritmos antes vistos.  \n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Categórico (Sin discr.)</b></td>\n",
    "    <td><b>85.30%</b></td>\n",
    "    <td>68.24%</td>\n",
    "    <td><b>73.77%</b></td>\n",
    "    <td><b>70.90%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Gaussiano</b></td>\n",
    "    <td>84.08%</td>\n",
    "    <td><b>74.23%</b></td>\n",
    "    <td>52.72%</td>\n",
    "    <td>61.65%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Categórico (discr.)</b></td>\n",
    "    <td>81.51%</td>\n",
    "    <td>60.87%</td>\n",
    "    <td>66.72%</td>\n",
    "    <td>63.66%</td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Comparativa</caption>\n",
    "</table>\n",
    "\n",
    "Podemos ver que suponer que los atributos reales tienen una distribución normal no es una buena aproximación.  \n",
    "No solo decrece la accuracy sino que decrece la métrica F1. Recordemos que esta le da igual importancia a la precision y al recall. Esta baja se debe a que el valor del recall decrece.  \n",
    "Al discretizar obtenemos mejores resultados que con Gauss, pero no mejores que al utilizar el algoritmo de Naive Bayes sin ningún tipo de variaciones.   \n",
    "Entendemos que los bins utilizados para la discretización son otro hiperparámetro a tener en cuenta en la validación cruzada, pero por temas de rendimiento decidimos no probarlo y usar un valor general para todas las pruebas, dado que la cantidad de bins variaría para cada atributo contínuo a considerar.  \n",
    "Como comprobación de que el primer algoritmo tiene mejores métricas, supusimos que aumentando la cantidad de bins estaríamos más cerca de las métricas obtenidas para el Naive Bayes sin variaciones y efectivamente fue lo que sucedió.  \n",
    "Las métricas obtenidas con 50 bins fueron las siguientes:   \n",
    "  \n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>50 Bins</b></td>\n",
    "    <td><b>83.16%</b></td>\n",
    "    <td><b>63.98%</b></td>\n",
    "    <td><b>70.05%</b></td>\n",
    "    <td><b>66.88%</b></td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Aumento de bins</caption>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Implementaciones de Scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ejecuciones presentadas a continuación son realizadas habiendo sacado los atributos ‘fnlwgt’ y ‘relationship’, utilizando 5 folds y con los datos del conjunto de entrenamiento normalizados, o discretizados en 10 bins según corresponda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Ejecución de KNN de Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import scikit\n",
    "import utils\n",
    "\n",
    "########## PARÁMETROS DE EJECUCIÓN ##########\n",
    "\n",
    "SEED = 3\n",
    "DISCR = 0             # Cantidad de bins utilizado para la discretización de los atributos continuos\n",
    "NORM = 1               # 1 si se quiere normalizar, 0 en caso contrario\n",
    "TSET_PERCENTAGE = 0.8  # Proporción utilizada para el set de entrenamiento\n",
    "K = 11                 # Cantidad de vecinos para KNN\n",
    "\n",
    "params = [DISCR, NORM, TSET_PERCENTAGE]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "training_examples, training_classes, evaluation_examples, evaluation_classes, training_set, evaluation_set = utils.prepare_data(*params)\n",
    "\n",
    "logging.info(f\"Ejecutando KNN de Scikit...\")\n",
    "classifier_knn = scikit.scikit_knn(training_examples, training_classes, k=K)\n",
    "obtained_classes_knn = scikit.classify_examples(classifier_knn, evaluation_examples)\n",
    "metrics = utils.get_metrics(obtained_classes_knn, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"KNN de Scikit finalizado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Validación cruzada con KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se utilizó la implementación KNeighborsClassifier de Scikit, solamente con los datos normalizados.\n",
    "\n",
    "Se realizó validación cruzada probando sobre valores de k entre 1 y 15.\n",
    "\n",
    "Los resultados obtenidos fueron los siguientes:\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    " <tr>\n",
    "    <th></th>\n",
    "      <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>k=1</td>\n",
    "    <td>80.63%</td>\n",
    "    <td>59.16%</td>\n",
    "    <td>60.59%</td>\n",
    "    <td>59.86%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=3</td>\n",
    "    <td>82.71%</td>\n",
    "    <td>64.52%</td>\n",
    "    <td>61.06%</td>\n",
    "    <td>62.73%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=5</td>\n",
    "    <td>83.67%</td>\n",
    "    <td>67.17%</td>\n",
    "    <td>61.67%</td>\n",
    "    <td>64.30%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k=7</td>\n",
    "    <td>84.07%</td>\n",
    "    <td>68.42%</td>\n",
    "    <td>61.67%</td>\n",
    "    <td>64.86%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>k=9</b></td>\n",
    "    <td><b>84.39%</b></td>\n",
    "    <td><b>69.34%</b></td>\n",
    "    <td><b>62.00%</b></td>\n",
    "    <td><b>65.46%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>k=11</b></td>\n",
    "    <td><b>84.61%</b></td>\n",
    "    <td><b>70.06%</b></td>\n",
    "    <td><b>61.99%</b></td>\n",
    "    <td><b>65.77%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>k=13</b></td>\n",
    "    <td><b>84.57%</b></td>\n",
    "    <td><b>70.05%</b></td>\n",
    "    <td><b>61.70%</b></td>\n",
    "    <td><b>65.61%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>k=15</b></td>\n",
    "    <td><b>84.64%</b></td>\n",
    "    <td><b>70.17%</b></td>\n",
    "    <td><b>61.89%</b></td>\n",
    "    <td><b>65.77%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla - KNN Scikit. </caption>\n",
    "</table>\n",
    "\n",
    "\n",
    "Al igual que en nuestra implementación de KNN, los valores óptimos los obtenemos a partir de k = 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Ejecución de Naive Bayes de Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import scikit\n",
    "import utils\n",
    "\n",
    "########## PARÁMETROS DE EJECUCIÓN ##########\n",
    "\n",
    "SEED = 3\n",
    "DISCR = 0              # Cantidad de bins utilizado para la discretización de los atributos continuos\n",
    "NORM = 0               # 1 si se quiere normalizar, 0 en caso contrario\n",
    "TSET_PERCENTAGE = 0.8  # Proporción utilizada para el set de entrenamiento\n",
    "M = 1                  # Parámetro m de suavizado categórico\n",
    "\n",
    "params = [DISCR, NORM, TSET_PERCENTAGE]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "training_examples, training_classes, evaluation_examples, evaluation_classes, training_set, evaluation_set = utils.prepare_data(*params)\n",
    "\n",
    "logging.info(f\"Ejecutando Naive Bayes de Scikit...\")\n",
    "classifier_nb_cont = scikit.scikit_nb(training_examples, training_classes, nb_type='gaussian')\n",
    "obtained_classes_nb = scikit.classify_examples(classifier_nb_cont, evaluation_examples)\n",
    "logging.info(f\"\")\n",
    "logging.info(f\"Resultados Naive Bayes Gaussiano con Scikit:\")\n",
    "metrics = utils.get_metrics(obtained_classes_nb, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"\")\n",
    "\n",
    "classifier_nb_cat = scikit.scikit_nb(training_examples, training_classes, nb_type='categorical', m=M)\n",
    "obtained_classes_nb = scikit.classify_examples(classifier_nb_cat, evaluation_examples)\n",
    "logging.info(f\"\")\n",
    "logging.info(f\"Resultados Naive Bayes Categórico con Scikit:\")\n",
    "metrics = utils.get_metrics(obtained_classes_nb, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"\")\n",
    "\n",
    "classifier_nb_cont_mixed, classifier_nb_cat_mixed = scikit.mixed_nb(training_examples, training_classes, m=M)\n",
    "obtained_classes_mixed_nb = scikit.mixed_classify_examples(classifier_nb_cont_mixed, classifier_nb_cat_mixed, evaluation_examples)\n",
    "logging.info(f\"Resultados Naive Bayes mezclado Scikit:\")\n",
    "metrics = utils.get_metrics(obtained_classes_mixed_nb, evaluation_classes)\n",
    "utils.print_metrics(metrics)\n",
    "logging.info(f\"\")\n",
    "logging.info(f\"Naive Bayes de Scikit finalizado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. Validación cruzada con Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Naive Bayes se probaron varios clasificadores de los provistos por Scikit. En particular, se probaron el **gaussiano** (GaussianNB) y el **categórico** (CategoricalNB).\n",
    "\n",
    "Además, dado que Scikit no provee de un clasificador que permita trabajar tanto con datos continuos como continuos, se implementó un clasificador **híbrido**, el cual genera un clasificador para cada tipo de atributo (categórico y contínuo) con el objetivo de mejorar los resultados (nota: esto último se hizo antes de saber que los atributos del dataset no siguen una distribución gaussiana), y luego, aprovechando la independencia entre probabilidades, simplemente multiplica las probabilidades obtenidas por cada clasificador.\n",
    "\n",
    "Para los casos del clasificador categórico y el híbrido, se probaron con validación cruzada distintos valores de m para generar suavizado categórico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4.1. Implementación sin discretización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4.1.1. Naive Bayes Categórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.001</b></td>\n",
    "    <td><b>85.22%</b></td>\n",
    "    <td><b>67.88%</b></td>\n",
    "    <td><b>72.82%</b></td>\n",
    "    <td><b>70.26%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.01</b></td>\n",
    "    <td><b>85.20%</b></td>\n",
    "    <td><b>67.83%</b></td>\n",
    "    <td><b>72.80%</b></td>\n",
    "    <td><b>70.22%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 0.1</td>\n",
    "    <td>85.09%</td>\n",
    "    <td>67.59%</td>\n",
    "    <td>72.63%</td>\n",
    "    <td>70.02%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 0.4</td>\n",
    "    <td>84.98%</td>\n",
    "    <td>67.40%</td>\n",
    "    <td>72.34%</td>\n",
    "    <td>69.78%</td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Naive Bayes categórico</caption>\n",
    "</table>\n",
    "\n",
    "Se puede notar que los mejores resultados se obtienen con los valores 0.001 y 0.01.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4.1.2. Naive Bayes Híbrido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.001</b></td>\n",
    "    <td><b>82.08%</b></td>\n",
    "    <td><b>70.62%</b></td>\n",
    "    <td><b>43.29%</b></td>\n",
    "    <td><b>53.67%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.01</b></td>\n",
    "    <td><b>82.08%</b></td>\n",
    "    <td><b>70.62%</b></td>\n",
    "    <td><b>43.29%</b></td>\n",
    "    <td><b>53.67%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.1</b></td>\n",
    "    <td><b>82.08%</b></td>\n",
    "    <td><b>70.63%</b></td>\n",
    "    <td><b>43.30%</b></td>\n",
    "    <td><b>53.67%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.4</b></td>\n",
    "    <td><b>82.08%</b></td>\n",
    "    <td><b>70.63%</b></td>\n",
    "    <td><b>43.29%</b></td>\n",
    "    <td><b>53.67%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 1</td>\n",
    "    <td>82.08%</td>\n",
    "    <td>70.62%</td>\n",
    "    <td>43.26%</td>\n",
    "    <td>53.46%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 1</td>\n",
    "    <td>82.03%</td>\n",
    "    <td>70.53%</td>\n",
    "    <td>43.07%</td>\n",
    "    <td>53.46%</td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Naive Bayes híbrido</caption>\n",
    "</table>\n",
    "\n",
    "Se puede ver que los resultados obtenidos con m menores a 0.4 tienden a ser iguales (al menos hasta 0.001). Los mejores dan un F1=53.67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4.2. Implementación discretizada (10 bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4.2.1. Naive Bayes Categórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 0.1</td>\n",
    "    <td>81.57%</td>\n",
    "    <td>60.51%</td>\n",
    "    <td>66.71%</td>\n",
    "    <td>63.45%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>m = 0.4</b></td>\n",
    "    <td><b>81.58%</b></td>\n",
    "    <td><b>60.52%</b></td>\n",
    "    <td><b>66.74%</b></td>\n",
    "    <td><b>63.47%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 1</td>\n",
    "    <td>81.57%</td>\n",
    "    <td>60.50%</td>\n",
    "    <td>66.73%</td>\n",
    "    <td>63.45%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 5</td>\n",
    "    <td>81.50%</td>\n",
    "    <td>60.39%</td>\n",
    "    <td>66.49%</td>\n",
    "    <td>63.29%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m = 10</td>\n",
    "    <td>81.48%</td>\n",
    "    <td>60.42%</td>\n",
    "    <td>66.06%</td>\n",
    "    <td>63.11%</td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Naive Bayes categórico</caption>\n",
    "</table>\n",
    "\n",
    "Aquí se puede observar que los resultados se mantienen bastante estables dentro del rango de 0.1 a 5. Los mejores resultados en términos de F1 se dan con m=0.4, donde se obtiene un F1=63.47%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. Evaluación comparativa entre implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos al evaluar con el conjunto de entrenamiento de los tres clasificadores fueron los siguientes (el m elegido para los clasificadores con discretización fue 0.4, para los sin discretización fue 0.001):\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Gaussiano</b></td>\n",
    "    <td>79.77%</td>\n",
    "    <td>56.01%</td>\n",
    "    <td>68.72%</td>\n",
    "    <td>61.72%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Categórico (discr.)</b></td>\n",
    "    <td>81.82%</td>\n",
    "    <td>60.36%</td>\n",
    "    <td>68.12%</td>\n",
    "    <td>64.00%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Categórico (s/discr.)</b></td>\n",
    "    <td><b>85.10%</b></td>\n",
    "    <td>66.97%</td>\n",
    "    <td><b>73.38%</b></td>\n",
    "    <td><b>70.03%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NB Híbrido (s/discr.)</b></td>\n",
    "    <td>81.31%</td>\n",
    "    <td><b>67.45%</b></td>\n",
    "    <td>41.03%</td>\n",
    "    <td>51.02%</td>\n",
    "  </tr>\n",
    "  <caption>Tabla - Comparativa</caption>\n",
    "</table>\n",
    "\n",
    "Los mejores resultados en términos de F1 (70.03%) se obtienen con la versión categórica sin discretizar.\n",
    "\n",
    "Algo interesante a observar aquí es el hecho de que se obtienen mejores resultados con el Naive Bayes categórico, que con el Naive Bayes híbrido. Como se mencionó anteriormente, los datos no siguen una distribución normal. Esto podría explicar por qué las métricas obtenidas con la implementación híbrida no son tan buenas. De cualquier manera cabe destacar que el híbrido supera en términos de precision al categórico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Comparación final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados presentados a continuación corresponden a la ejecución de las mejores versiones obtenidas de las partes anteriores. \n",
    "\n",
    "Algunas cuestiones a tomar en cuenta sobre los resultados:\n",
    "- Son obtenidos a partir de una partición del dataset en 80% de entrenamiento y 20% de evaluación.\n",
    "- Los hiper-parámetros utilizados en cada parte corresponden a los mejores obtenidos en las etapas de validación cruzada.\n",
    "- Están discretizados con 10 bins (salvo el KNN de scikit).\n",
    "- No están los atributos “fnlwgt” y “relationship”.\n",
    "- Las ejecuciones de los KNN son con los atributos normalizados.\n",
    "\n",
    "Comparación final para los algoritmos de KNN:\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>KNN Nuestro, K = 9</b></td>\n",
    "    <td><b>84.49%</b></td>\n",
    "    <td><b>69.81%</b></td>\n",
    "    <td><b>63.60%</b></td>\n",
    "    <td><b>66.56%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>KNN Scikit, K = 9</td>\n",
    "    <td>84.44%</td>\n",
    "    <td>69.74%</td>\n",
    "    <td>63.39%</td>\n",
    "    <td>66.42%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>KNN Nuestro, K = 11</b></td>\n",
    "    <td><b>84.71%</b></td>\n",
    "    <td><b>70.54%</b></td>\n",
    "    <td><b>63.52%</b></td>\n",
    "    <td><b>66.84%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>KNN Scikit, K = 11</td>\n",
    "    <td>84.70%</td>\n",
    "    <td>70.54%</td>\n",
    "    <td>63.39%</td>\n",
    "    <td>66.79%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>KNN Nuestro, K = 13</td>\n",
    "    <td>84.85%</td>\n",
    "    <td>70.85%</td>\n",
    "    <td>63.85%</td>\n",
    "    <td>67.17%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>KNN Scikit, K = 13</b></td>\n",
    "    <td><b>84.91%</b></td>\n",
    "    <td><b>70.99%</b></td>\n",
    "    <td><b>63.98%</b></td>\n",
    "    <td><b>67.30%</b></td>\n",
    "  </tr> \n",
    "   <caption>Tabla - Comparación final, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "Comparación final para los algoritmos de Naive Bayes:\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Naive Bayes nuestro (s/discr.)</b></td>\n",
    "    <td><b>85.30%</b></td>\n",
    "    <td><b>68.24%</b></td>\n",
    "    <td><b>73.77%</b></td>\n",
    "    <td><b>70.90%</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Naive Bayes Scikit (s/discr.)</td>\n",
    "    <td>85.10%</td>\n",
    "    <td>66.97%</td>\n",
    "    <td>73.38%</td>\n",
    "    <td>70.03%</td>\n",
    "  </tr>\n",
    "   <caption>Tabla - Comparación final, d = 80/20</caption>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas conclusiones generales y posibles mejoras en las evaluaciones:\n",
    "\n",
    "- Utilizando el algoritmo de Naive Bayes, nos llamo la atención que se obtuvieran los mejores resultados cuando se  trata a los atributos continuos como si fueran discretos, sin aplicarle ningún tipo de disretización.\n",
    "  Esto nos llevo a observar cuantos valores diferentes existían para cada atributo continuo y los mismos fueron: age 43 valores distintos,education-num 13,capital-gain 5,capital-loss 3 y hours-per-week 18.  \n",
    "  Creemos que los resultados en las métricas se deben al comportamiento de cada atributo, por ejemplo el rango de edades de personas habilitadas a trabajar podría ser de 18 a 65 años, lo cual nos da 47 valores posibles.\n",
    "  Tomando una muestra muy grande de personas es altamente probable que muchas tengan la misma edad, y al calcular la probabilidad (utilizando la frecuencia sobre el total) de tener cierta edad dada una categoria, ésta seguramente no sea pequeña.\n",
    "  Por otra parte, si por ejemplo el atributo fuera la altura medida en metros,centimetros y milimetros donde la probabilidad de que varias personas tengan exactamente la misma altura es muy pequeña, seguramente sea más conveniente usar gauss. \n",
    "  Consideramos que esto tambien ocurre sobre el resto de atribitos continuos, con lo cual podemos concluir que se comportan como categóricos, dada su baja variación en los posibles valores a tomar, a pesar de ser numéricos.\n",
    "- Una posible mejora deberia ser la forma en la que elegimos la cantidad bins para discretizar cada atributo continuo, utilizando validación cruzada para encontrar el valor óptimo correspondiente a cada atributo. \n",
    "- Con respecto algoritmo KNN, como observamos en la comparación final con scikit, obtuvimos practicamente los mismos resultados. Intentamos utilizar otros cálculos para la distancia, pero no llegamos a buen puerto, y terminamos optando por plasmar en el informe solamente la experimentación con la distancia euclidea.\n",
    "- Por otra parte, siguiendo con KNN, probamos la implementación de un sistema de ponderación, en el cuál se le asignaba más peso a los vecinos más cercanos respecto de los más lejanos (cercanos y lejanos dentro de los \"k\" ya seleccionados). Además, se trabajó tanto con valores de \"k\" pares como impares; pero no obtuvimos buenos resultados. En ningún caso las métricas se aproximaron a los valores que presentamos en el informe.\n",
    "- De todas formas, consideramos que los resultados obtenidos son relativamente buenos, ya que los atributos que presenta el conjunto de datos no son del todo representativos. Quizás nos faltó analizar más en detalle el conjunto de datos, y determinar el \"peso\" de un atributo en relación a otros, por ejemplo:\n",
    "    Es razonable que una persona a los 50 años de edad, perciba más ingresos que una persona de 20, 25 años; pero esto debería estar fuertemente relacionado con la formación de cada persona.\n",
    "    En las pruebas que realizamos, pudimos observar que tanto la edad como la cantidad de horas de trabajo de una persona, fueron los atributos que nos ayudaron a obtener métricas más acertadas (realizando validación cruzada sin estos atributos, las métricas disminuían notoriamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
